{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX8uT696oJm5vE/fIAklOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atharv24-Atreus/Pattern_Recogination-/blob/main/PatternExp9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e07CjdVeMqnD",
        "outputId": "c96d0603-1bd0-4d13-f969-41f5eb17a7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      92.0\n",
            "           1       0.00      0.00      0.00      95.0\n",
            "           2       0.00      0.00      0.00      86.0\n",
            "           3       0.00      0.00      0.00      80.0\n",
            "           4       0.00      0.00      0.00      95.0\n",
            "           5       0.00      0.00      0.00      85.0\n",
            "           6       0.00      0.00      0.00      97.0\n",
            "           7       0.00      0.00      0.00      69.0\n",
            "           8       0.00      0.00      0.00      89.0\n",
            "           9       0.00      0.00      0.00      78.0\n",
            "          10       0.00      0.00      0.00      99.0\n",
            "          11       0.00      0.00      0.00      65.0\n",
            "          12       0.00      0.00      0.00      78.0\n",
            "          13       0.00      0.00      0.00      81.0\n",
            "          14       0.00      0.00      0.00     100.0\n",
            "          15       0.00      0.00      0.00      83.0\n",
            "          16       0.00      0.00      0.00      88.0\n",
            "          17       0.00      0.00      0.00      90.0\n",
            "          18       0.00      0.00      0.00      90.0\n",
            "          19       0.00      0.00      0.00      90.0\n",
            "          20       0.00      0.00      0.00      95.0\n",
            "          21       0.00      0.00      0.00      93.0\n",
            "          22       0.00      0.00      0.00      96.0\n",
            "          23       0.00      0.00      0.00      87.0\n",
            "          24       0.00      0.00      0.00      74.0\n",
            "          25       0.00      0.00      0.00      86.0\n",
            "          26       0.00      0.00      0.00      81.0\n",
            "          27       0.00      0.00      0.00      76.0\n",
            "          28       0.00      0.00      0.00      83.0\n",
            "          29       0.00      0.00      0.00      75.0\n",
            "          30       0.00      0.00      0.00      87.0\n",
            "          31       0.00      0.00      0.00      85.0\n",
            "          32       0.00      0.00      0.00      88.0\n",
            "          33       0.00      0.00      0.00      90.0\n",
            "          34       0.00      0.00      0.00      82.0\n",
            "          35       0.00      0.00      0.00     161.0\n",
            "          36       0.00      0.00      0.00      96.0\n",
            "          37       0.00      0.00      0.00      86.0\n",
            "\n",
            "    accuracy                           0.00    3351.0\n",
            "   macro avg       0.00      0.00      0.00    3351.0\n",
            "weighted avg       0.00      0.00      0.00    3351.0\n",
            "\n",
            "Sample predicted items: ['lunch meat' 'vegetables' 'butter' 'mixes' 'all- purpose' 'ketchup'\n",
            " 'sugar' 'paper towels' 'ice cream' 'paper towels']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and clean dataset\n",
        "df = pd.read_csv(\"dataset_group.csv\")\n",
        "df.columns = ['date', 'customer_id', 'item']\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Drop rows where date conversion failed\n",
        "df = df.dropna(subset=['date'])\n",
        "\n",
        "# Feature Engineering\n",
        "df['day'] = df['date'].dt.day\n",
        "df['month'] = df['date'].dt.month\n",
        "df['weekday'] = df['date'].dt.weekday\n",
        "\n",
        "# Encode the target labels\n",
        "le = LabelEncoder()\n",
        "df['item_encoded'] = le.fit_transform(df['item'])\n",
        "\n",
        "# Use only numeric features (no raw 'date')\n",
        "X = df[['customer_id', 'day', 'month', 'weekday']]\n",
        "y = df['item_encoded']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Reverse transform predictions to original item names\n",
        "predicted_items = le.inverse_transform(y_pred[:10])\n",
        "print(\"Sample predicted items:\", predicted_items)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74oNI30_M-Nk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}